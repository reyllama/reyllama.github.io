
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>MixDL</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

        <!--FACEBOOK-->
    <meta property="og:image" content="https://jonbarron.info/mipnerf/img/rays_square.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://reyllama.github.io/MixDL"/>
    <meta property="og:title" content="Fashion-Diffusion" />
    <meta property="og:description" content="Project page for Unifying Vision-Language Representation Space with Single-tower Transformer" />

        <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="mip-NeRF" />
    <meta name="twitter:description" content="Project page for Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields." />
    <meta name="twitter:image" content="https://jonbarron.info/mipnerf/img/rays_square.png" />


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <!-- <link rel="icon" type="image/png" href="img/seal_icon.png"> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                Few-shot Image Generation with Mixup-based Distance Learning</br>
                <small>
                    ECCV 2022
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://reyllama.github.io">
                          Chaerin Kong
                        </a>
                        </br>Seoul National University
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=FbufdJ8AAAAJ&hl=ko">
                          Jeesoo Kim
                        </a>
                        </br>NAVER WEBTOON
                    </li>
                    <li>
                        <a href="http://mipal.snu.ac.kr/index.php/Donghoon_Han">
                            Donghoon Han
                        </a>
                        </br>Seoul National University
                    </li>
                    <li>
                        <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">
                          Nojun Kwak
                        </a>
                        </br>Seoul National University
                    </li>
                </ul>
            </div>
        </div>


<!--        <div class="row">-->
<!--                <div class="col-md-4 col-md-offset-4 text-center">-->
<!--                    <ul class="nav nav-pills nav-justified">-->
<!--                        <li>-->
<!--                            <a href="https://arxiv.org/abs/2103.13415">-->
<!--                            <image src="img/mip_paper_image.jpg" height="60px">-->
<!--                                <h4><strong>Paper</strong></h4>-->
<!--                            </a>-->
<!--                        </li>-->
<!--                        <li>-->
<!--                            <a href="https://youtu.be/EpH175PY1A0">-->
<!--                            <image src="img/youtube_icon.png" height="60px">-->
<!--                                <h4><strong>Video</strong></h4>-->
<!--                            </a>-->
<!--                        </li>-->
<!--                        <li>-->
<!--                            <a href="https://github.com/google/mipnerf">-->
<!--                            <image src="img/github.png" height="60px">-->
<!--                                <h4><strong>Code</strong></h4>-->
<!--                            </a>-->
<!--                        </li>-->
<!--                    </ul>-->
<!--                </div>-->
<!--        </div>-->



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <image src="img/eccv_main.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify">
                    Producing diverse and realistic images with generative models such as GANs typically requires large scale training with vast amount of images. GANs trained with limited data can easily memorize few training samples and display undesirable properties
                    like stairlike latent space where interpolation in the latent space yields discontinuous transitions in the output space. In this work, we consider a challenging task of pretraining-free few-shot image synthesis, and seek to train existing generative
                    models with minimal overfitting and mode collapse. We propose mixup-based distance regularization on the feature space of both a generator and the counterpart discriminator that encourages the two players to reason not only about the scarce observed
                    data points but the relative distances in the feature space they reside. Qualitative and quantitative evaluation on diverse datasets demonstrates that our method is generally applicable to existing models to enhance both fidelity and diversity under few-shot setting.
                </p>
            </div>
        </div>



<!--        <div class="row">-->
<!--            <div class="col-md-8 col-md-offset-2">-->
<!--                <h3>-->
<!--                    Video-->
<!--                </h3>-->
<!--                <div class="text-center">-->
<!--                    <div style="position:relative;padding-top:56.25%;">-->
<!--                        <iframe src="https://www.youtube.com/embed/EpH175PY1A0" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>-->
<!--                    </div>-->
<!--                </div>-->
<!--            </div>-->
<!--        </div>-->


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Stairlike Latent Space and Mixup-based Distance Learning (MixDL)
                </h3>
                <br>
                <image src="img/stairlike.png" class="img-responsive" alt="overview">
                <p>
                    Generative models trained with extremely few data samples (<em>e.g.,</em> n=10) strongly overfits, being able to produce only a limited set of <em>seen</em> data points. This results in <em>stairlike</em> latent space geometry,
                    under which gradual transition in the latent space results in discontinuous changes in the output (image) space. Thus, obtaining sample diversity is key to few-shot generative modeling while fidelity is a relatively low hanging fruit. <br><br>
                    In this work, instead of directly tackling the seemingly insurmountable problem of memorization, we set a surrogate objective of <em>smoothing</em> the generative latent space to enable sampling of diverse perceptually <em>in-between</em> samples.
                    To that end, we intentionally generate an anchor sample by applying mixup in the latent space, and explicitly enforce the pairwise similarity distributions between the anchor sample and normal samples to follow the mixup coefficient. Intuitively,
                    if we have four normal samples and mixup coefficient of (0.4, 0.3, 0.2, 0.1), the normalized pairwise similarities between the mixup sample and the rest should also roughly be (0.4, 0.3, 0.2, 0.1). We formulate this with intermediate feature cosine-similarities
                    and Kullback-Leibler Divergence. Consult to the main paper for more details.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Quantitative Results
                </h3>
                <p>
                    We compare our method with various competitive baselines on diverse benchmarks. We mainly use Frechet Inception Distance (FID), LPIPS, sFID, Precision and Recall for the evaluation metric.
                </p><br>
                <image src="img/Mixdl_tab1.png" class="img-responsive" alt="overview"></image><br>
                <image src="img/Mixdl_tab2.png" class="img-responsive" alt="overview" width="80%"></image><br>
                <image src="img/Mixdl_tab3.png" class="img-responsive" alt="overview" width="90%"></image>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Qualitative Results
                </h3>
                <p>
                    We present generated samples form ours and the baselines. As opposed to baselines that strictly generate memorized samples, MixDL enables sampling of novel unseen images.
                </p><br>
                <image src="img/Mixdl_qual1.png" class="img-responsive" alt="overview" width="90%"></image>
                <image src="img/Mixdl_qual2.png" class="img-responsive" alt="overview"></image>
            </div>
        </div>




<!--        <div class="row">-->
<!--            <div class="col-md-8 col-md-offset-2">-->
<!--                <h3>-->
<!--                    Citation-->
<!--                </h3>-->
<!--                <div class="form-group col-md-10 col-md-offset-1">-->
<!--                    <textarea id="bibtex" class="form-control" readonly>-->
<!--@article{barron2021mipnerf,-->
<!--    title={Mip-NeRF: A Multiscale Representation -->
<!--           for Anti-Aliasing Neural Radiance Fields},-->
<!--    author={Jonathan T. Barron and Ben Mildenhall and -->
<!--            Matthew Tancik and Peter Hedman and -->
<!--            Ricardo Martin-Brualla and Pratul P. Srinivasan},-->
<!--    journal={ICCV},-->
<!--    year={2021}-->
<!--}</textarea>-->
<!--                </div>-->
<!--            </div>-->
<!--        </div>-->

<!--        <div class="row">-->
<!--            <div class="col-md-8 col-md-offset-2">-->
<!--                <h3>-->
<!--                    Acknowledgements-->
<!--                </h3>-->
<!--                <p class="text-justify">-->
<!--                We thank Janne Kontkanen and David Salesin for their comments on the text, Paul Debevec for constructive discussions, and Boyang Deng for JaxNeRF. -->
<!--                    <br>-->
<!--                MT is funded by an NSF Graduate Fellowship.-->
<!--                    <br>-->
<!--                The website template was borrowed from <a href="http://mgharbi.com/">MichaÃ«l Gharbi</a>.-->
<!--                </p>-->
<!--            </div>-->
<!--        </div>-->
    </div>
</body>
</html>
